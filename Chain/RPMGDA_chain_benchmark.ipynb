{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M84h1AoxSMEz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import copy\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.datasets\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "S8caL0GBUbGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "3_ITBIIVjF44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "KAwXMaRJyhN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "california_housing = fetch_california_housing(as_frame=True)"
      ],
      "metadata": {
        "id": "oNIbeWHzWDDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "california_housing.frame.head()"
      ],
      "metadata": {
        "id": "V7zAK79-nYjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = california_housing.data\n",
        "Y = california_housing.target"
      ],
      "metadata": {
        "id": "X5fUMm6zn7NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reorder the features\n",
        "X = X[['Longitude', 'Latitude', 'AveOccup',  'Population', 'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms']]"
      ],
      "metadata": {
        "id": "og3MVCa5nZnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(X.columns)\n",
        "print(features)"
      ],
      "metadata": {
        "id": "3WRdaSpcoRB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qyWDvJz0h0PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "KXsH5U5wjRlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit a linear regression model to set the bias b\\\n",
        "Or equivalently, set b = Y_train.mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "lMOp3yo9rETI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "b = model.intercept_\n",
        "print(b)"
      ],
      "metadata": {
        "id": "DomeUfYTrD2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask1 = [True, True, False, False, False, False, False, False]\n",
        "mask2 = [True, True, True, True, True, False, False, False]\n",
        "mask3 = [False, False, True, True, True, True, True, True]\n",
        "mask4 = [False, False, False, False, False, True, True, True]"
      ],
      "metadata": {
        "id": "q_FccjIwvZYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func1(X_train, Y_train, w, b, mask = mask1):\n",
        "    X_masked = X_train.copy()\n",
        "    X_masked[:, ~np.array(mask)] = 0\n",
        "    predictions = np.dot(X_masked, w) + b\n",
        "    mse_loss = np.mean((Y_train - (np.dot(X_masked, w) + b))**2)\n",
        "    grad_w = 2 * X_masked.T @ (predictions - Y_train) / len(Y_train)\n",
        "    return mse_loss, grad_w\n"
      ],
      "metadata": {
        "id": "yxxYYiFCpAIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func2(X_train, Y_train, w, b, mask = mask2):\n",
        "    X_masked = X_train.copy()\n",
        "    X_masked[:, ~np.array(mask)] = 0\n",
        "    predictions = np.dot(X_masked, w) + b\n",
        "    mse_loss = np.mean((Y_train - (np.dot(X_masked, w) + b))**2)\n",
        "    grad_w = 2 * X_masked.T @ (predictions - Y_train) / len(Y_train)\n",
        "    return mse_loss, grad_w"
      ],
      "metadata": {
        "id": "nyJ-RsuDwLah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func3(X_train, Y_train, w, b, mask = mask3):\n",
        "    X_masked = X_train.copy()\n",
        "    X_masked[:, ~np.array(mask)] = 0\n",
        "    predictions = np.dot(X_masked, w) + b\n",
        "    mse_loss = np.mean((Y_train - (np.dot(X_masked, w) + b))**2)\n",
        "    grad_w = 2 * X_masked.T @ (predictions - Y_train) / len(Y_train)\n",
        "    return mse_loss, grad_w"
      ],
      "metadata": {
        "id": "Ufk7xWJMt5bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func4(X_train, Y_train, w, b, mask = mask4):\n",
        "    X_masked = X_train.copy()\n",
        "    X_masked[:, ~np.array(mask)] = 0\n",
        "    predictions = np.dot(X_masked, w) + b\n",
        "    mse_loss = np.mean((Y_train - (np.dot(X_masked, w) + b))**2)\n",
        "    grad_w = 2 * X_masked.T @ (predictions - Y_train) / len(Y_train)\n",
        "    return mse_loss, grad_w"
      ],
      "metadata": {
        "id": "YIgm7KFst7ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MGDA implementation"
      ],
      "metadata": {
        "id": "iBga1I5SxljU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sz(a,b):\n",
        "  # find the minimizer of ax^2 + 2bx, where 0<=x<=1 (x is step size)\n",
        "\n",
        "  # check that a is non negative\n",
        "  if a < 0 :\n",
        "    print(\"error in solving step size\")\n",
        "    return -1\n",
        "  if a == 0:\n",
        "    if b >=0 :\n",
        "      sz = 0\n",
        "    else:\n",
        "      sz = 1\n",
        "    return sz\n",
        "\n",
        "  axis = - b * 1.0 / a\n",
        "  if axis < 0 :\n",
        "    sz = 0\n",
        "  elif axis > 1:\n",
        "    sz = 1\n",
        "  else:\n",
        "    sz = axis\n",
        "  return sz"
      ],
      "metadata": {
        "id": "_nQAVifzxkse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write a FW procedure to solve for the min norm element\n",
        "def FW_solve_w(U, rounds=10, lambda_0=None):\n",
        "  # Frank-Wolfe exact step size, with warm start\n",
        "\n",
        "\n",
        "  n,d = U.shape\n",
        "  lbd = 1.0/n * np.ones(n)\n",
        "\n",
        "  if lambda_0 is not None:\n",
        "    lbd = lambda_0\n",
        "\n",
        "  # precomputing G here is actually better since it can be reused in the loop,\n",
        "  # otherwise matrix/matrix multiplication (UU^T) is not efficient\n",
        "  G = np.array(U.dot(U.T))\n",
        "\n",
        "  for t in range(rounds):\n",
        "    v = G.dot(lbd)\n",
        "    idx_min = np.argmin(v)\n",
        "    d = np.zeros(n,dtype=float)\n",
        "    d[idx_min] = 1\n",
        "\n",
        "    # find the best sz by solving a quadratic problem\n",
        "    delta = d - lbd\n",
        "    a = delta.dot(G.dot(delta))\n",
        "    b = delta.dot(v)\n",
        "    sz = find_sz(a,b)\n",
        "    if sz < 0:\n",
        "      sys.exit(\"error in running FW for solving QP\")\n",
        "\n",
        "    lbd = (1-sz) * lbd + sz * d\n",
        "    if sz == 0:\n",
        "      # print(\"it takes ith round:\",t)\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "  return U.T.dot(lbd), lbd"
      ],
      "metadata": {
        "id": "h3eylv3fx7qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single trial (i.e. seed)"
      ],
      "metadata": {
        "id": "umDUOWX2fk1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with MGDA"
      ],
      "metadata": {
        "id": "oHLY8S5AxJSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "w_0 = np.random.rand(8)"
      ],
      "metadata": {
        "id": "p3qIr2EauAsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "epoch = 500"
      ],
      "metadata": {
        "id": "7srdlMxtxbv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = w_0.copy()\n",
        "b = b\n",
        "list_losses = []\n",
        "for epoch in tqdm(range(epoch)):\n",
        "    losses = []\n",
        "    grads = []\n",
        "    for i in range(4):\n",
        "        loss, grad = eval(f\"func{i+1}\")(X_train, Y_train, w, b)\n",
        "        losses.append(loss)\n",
        "        grads.append(grad)\n",
        "\n",
        "    grads = np.array(grads)\n",
        "    common_grad, lbd = FW_solve_w(grads)\n",
        "\n",
        "    w = w - lr * common_grad\n",
        "    list_losses.append(losses)"
      ],
      "metadata": {
        "id": "omH3yiPEyl6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_store = w.copy()"
      ],
      "metadata": {
        "id": "JKS_PXLf2mXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mgda_list_losses = list_losses.copy()"
      ],
      "metadata": {
        "id": "NXdp6Ba31zh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mgda_list_losses[-1])"
      ],
      "metadata": {
        "id": "FbWpdmIn2c7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('chain_seed1_MGDA.pickle','wb') as f:\n",
        "    pickle.dump(mgda_list_losses,f)"
      ],
      "metadata": {
        "id": "TnqQAkoh7N3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Refine with RP-MGDA"
      ],
      "metadata": {
        "id": "81vzLaLn13uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "w_0 = np.random.rand(8)"
      ],
      "metadata": {
        "id": "jDg2tlbu1BQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "epoch = 5 # 5 is for refine"
      ],
      "metadata": {
        "id": "3xizSlMA186E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "\n",
        "# w = w_0.copy(), if training from start\n",
        "\n",
        "# For refining MGDA solution, use following\n",
        "w = w_store\n",
        "\n",
        "b = b\n",
        "list_losses = []\n",
        "for epoch in tqdm(range(epoch)):\n",
        "    losses = []\n",
        "    grads = []\n",
        "    for i in range(4):\n",
        "        loss, grad = eval(f\"func{i+1}\")(X_train, Y_train, w, b)\n",
        "        if epoch == 5:\n",
        "            print(grad)\n",
        "        losses.append(loss)\n",
        "        grads.append(grad)\n",
        "\n",
        "    # We do MGDA on theta_1 w[0:2] wrt (f1,f2)\n",
        "    f1_grad1 = grads[0][0:2]\n",
        "    f2_grad1 = grads[1][0:2]\n",
        "    common_g1 = FW_solve_w(np.array([f1_grad1, f2_grad1]))[0]\n",
        "\n",
        "    # We do MGDA on theta_2 w[2:5] wrt (f2,f3)\n",
        "    f2_grad2 = grads[1][2:5]\n",
        "    f3_grad2 = grads[2][2:5]\n",
        "    common_g2 = FW_solve_w(np.array([f2_grad2, f3_grad2]))[0]\n",
        "\n",
        "    # We do MGDA on theta_3 w[5:8] wrt (f3,f4)\n",
        "    f3_grad3 = grads[2][5:8]\n",
        "    f4_grad3 = grads[3][5:8]\n",
        "    common_g3 = FW_solve_w(np.array([f3_grad3, f4_grad3]))[0]\n",
        "\n",
        "    w[0:2] = w[0:2] - lr * common_g1\n",
        "    w[2:5] = w[2:5] - lr * common_g2\n",
        "    w[5:8] = w[5:8] - lr * common_g3\n",
        "\n",
        "    list_losses.append(losses)"
      ],
      "metadata": {
        "id": "R6KVer3r1_S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rpmgda_list_losses = list_losses.copy()"
      ],
      "metadata": {
        "id": "OtJNqJ9X6EM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('chain_seed1_RPMGDA.pickle','wb') as f:\n",
        "    pickle.dump(rpmgda_list_losses,f)"
      ],
      "metadata": {
        "id": "6NkvrlCkhHL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "wu6CgXsi8mZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After running 20 trials and saving the results\n",
        "With the 40 pickle files ready (20 seeds), we can run the following"
      ],
      "metadata": {
        "id": "c7aBAhaDhaJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "mgda_results = {}\n",
        "rpmgda_results = {}\n",
        "\n",
        "for seed in range(1, 21):\n",
        "  with open(f'chain_seed{seed}_MGDA.pickle', 'rb') as f:\n",
        "    mgda_results[seed] = pickle.load(f)\n",
        "  with open(f'chain_seed{seed}_RPMGDA.pickle', 'rb') as f:\n",
        "    rpmgda_results[seed] = pickle.load(f)"
      ],
      "metadata": {
        "id": "bmnCXmi8D0-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean and Stdev plots"
      ],
      "metadata": {
        "id": "Mg_AxnqSENQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code iterates over the four losses, calculates the mean and standard deviation of the losses across the 20 seeds for both MGDA and RPMGDA, and plots the means with shaded regions representing the standard deviations. Each loss is plotted in a separate subplot, with labels and legends for clarity."
      ],
      "metadata": {
        "id": "IfT6yt8rFrOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
        "loss_names = ['MSE ($f_1$)', 'MSE ($f_2$)', 'MSE ($f_3$)', 'MSE ($f_4$)']\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    mgda_losses = [np.array(mgda_results[seed])[:, i] for seed in range(1, 21)]\n",
        "    rpmgda_losses = [np.array(rpmgda_results[seed])[:, i] for seed in range(1, 21)]\n",
        "\n",
        "    mean_mgda = np.mean(mgda_losses, axis=0)\n",
        "    std_mgda = np.std(mgda_losses, axis=0)\n",
        "    mean_rpmgda = np.mean(rpmgda_losses, axis=0)\n",
        "    std_rpmgda = np.std(rpmgda_losses, axis=0)\n",
        "\n",
        "    ax.plot(mean_mgda, label='MGDA')\n",
        "    ax.fill_between(range(len(mean_mgda)), mean_mgda - std_mgda, mean_mgda + std_mgda, alpha=0.2)\n",
        "    ax.plot(mean_rpmgda, label='RPMGDA')\n",
        "    ax.fill_between(range(len(mean_rpmgda)), mean_rpmgda - std_rpmgda, mean_rpmgda + std_rpmgda, alpha=0.2)\n",
        "\n",
        "    ax.set_xlabel('Iteration',fontsize=18)\n",
        "    ax.set_ylabel(loss_names[i],fontsize=18)\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "    ax.legend(fontsize=16)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dljZ7spTVCyZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}